{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(r\"C:\\Users\\karan\\Downloads\\Data - 01.xlsx\")\n",
    "df2 = pd.read_excel(r\"C:\\Users\\karan\\Downloads\\Data - 02.xlsx\")\n",
    "df3 = pd.read_excel(r\"C:\\Users\\karan\\Downloads\\Data - 03.xlsx\")\n",
    "df4 = pd.read_excel(r\"C:\\Users\\karan\\Downloads\\Data - 04.xlsx\")\n",
    "df5 = pd.read_excel(r\"C:\\Users\\karan\\Downloads\\Data - 05.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.concat([df1,df2,df3,df4,df5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you for applying to the Junior Software ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you for your interest in the Train To Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eth, \\n\\nThank you for your interest in Exyn a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you for your interest in the Software En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi Seth,\\n\\nThank you for your interest in Pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>Blue skies and good self-care ahead... Manage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>If not, these fragrance will have you ready! M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>Colourful makeup that will literally bloom on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>Get access to your customized training plan th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>ðŸ”‘ Unlock all of our Coach features and take...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13640 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text\n",
       "0     Thank you for applying to the Junior Software ...\n",
       "1     Thank you for your interest in the Train To Hi...\n",
       "2     eth, \\n\\nThank you for your interest in Exyn a...\n",
       "3     Thank you for your interest in the Software En...\n",
       "4     Hi Seth,\\n\\nThank you for your interest in Pat...\n",
       "...                                                 ...\n",
       "1580  Blue skies and good self-care ahead... Manage ...\n",
       "1581  If not, these fragrance will have you ready! M...\n",
       "1582  Colourful makeup that will literally bloom on ...\n",
       "1583  Get access to your customized training plan th...\n",
       "1584  ðŸ”‘ Unlock all of our Coach features and take...\n",
       "\n",
       "[13640 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13640, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13640 entries, 0 to 1584\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    13634 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 213.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values\n",
    "df_merge.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate values\n",
    "df_merge.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "df_merge = df_merge.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13074, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')\n",
    "import string \n",
    "string.punctuation\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\karan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # not using this function since porter stemmer is aggresively preprocessing our data, hence will use POS tagging along with Lemmatization\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import PorterStemmer\n",
    "# import string\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# ps = PorterStemmer()\n",
    "\n",
    "# def transform_text1(text):\n",
    "#     if isinstance(text, str):\n",
    "#         text = text\n",
    "#         text = nltk.word_tokenize(text)\n",
    "\n",
    "#         y = []\n",
    "#         for i in text:\n",
    "#             if i.isalnum():\n",
    "#                 y.append(i)\n",
    "\n",
    "#         text = y[:]\n",
    "#         y.clear()\n",
    "\n",
    "#         for i in text:\n",
    "#             if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "#                 y.append(i)\n",
    "\n",
    "#         text = y[:]\n",
    "#         y.clear()\n",
    "\n",
    "#         for i in text:\n",
    "#             y.append(ps.stem(i))\n",
    "\n",
    "#         return \" \".join(y)\n",
    "#     else:\n",
    "#         return str(text)  # Convert non-string types to string\n",
    "\n",
    "# # Apply the modified transform_text function using lambda to the 'Text' column\n",
    "# df_merge['transformed_text'] = df_merge['Text'].apply(lambda x: transform_text1(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you for applying to the Junior Software ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you for your interest in the Train To Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eth, \\n\\nThank you for your interest in Exyn a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you for your interest in the Software En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi Seth,\\n\\nThank you for your interest in Pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>Blue skies and good self-care ahead... Manage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>If not, these fragrance will have you ready! M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>Colourful makeup that will literally bloom on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>Get access to your customized training plan th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>ðŸ”‘ Unlock all of our Coach features and take...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13074 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text\n",
       "0     Thank you for applying to the Junior Software ...\n",
       "1     Thank you for your interest in the Train To Hi...\n",
       "2     eth, \\n\\nThank you for your interest in Exyn a...\n",
       "3     Thank you for your interest in the Software En...\n",
       "4     Hi Seth,\\n\\nThank you for your interest in Pat...\n",
       "...                                                 ...\n",
       "1580  Blue skies and good self-care ahead... Manage ...\n",
       "1581  If not, these fragrance will have you ready! M...\n",
       "1582  Colourful makeup that will literally bloom on ...\n",
       "1583  Get access to your customized training plan th...\n",
       "1584  ðŸ”‘ Unlock all of our Coach features and take...\n",
       "\n",
       "[13074 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_list = [\"\\\\n\",\"\\\\t\",\"\\\\r\",\"â\",\"€\",\"™\",\"ð\",\"Ÿ\",\"ðŸ‘\",\"$\",\"â€™ll\",\"ƒ\",\"¢\",\"â€ƒ\",\"â€¢\",\"Â§\",\"§\",\"Â\",\"Ã¼\",\"Ã\",\"¼\",\"º\",\"œ\",\"˜\",\"£\",\"â€“\",\"â€œ\",\"&lt;#&gt;\",\"â€Œ\",\"ðŸŽ\",\"ð\",\"Ÿ\",\"Ž\",\"Í\",\"â€Œ ï»¿ Í\",\"ï»¿\",\"ðŸ”¨\",\"ðŸ¤©\",\"©\",\"¤\",\"±\",\"ðŸ˜±\",\"ðŸ˜±\",\" Í â€Œ ï»¿\",\"ÿ\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karan\\AppData\\Local\\Temp\\ipykernel_7852\\368490851.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df_merge['Text'] = df_merge['Text'].str.replace(w, '')\n",
      "C:\\Users\\karan\\AppData\\Local\\Temp\\ipykernel_7852\\368490851.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merge['Text'] = df_merge['Text'].str.replace(w, '')\n",
      "C:\\Users\\karan\\AppData\\Local\\Temp\\ipykernel_7852\\368490851.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_merge['Text'] = df_merge['Text'].str.replace(w, '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you for applying to the Junior Software ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you for your interest in the Train To Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eth, Thank you for your interest in Exyn and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you for your interest in the Software En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi Seth,Thank you for your interest in PathAI!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>Blue skies and good self-care ahead... Manage ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>If not, these fragrance will have you ready! M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>Colourful makeup that will literally bloom on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>Get access to your customized training plan th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>”‘ Unlock all of our Coach features and take y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13074 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text\n",
       "0     Thank you for applying to the Junior Software ...\n",
       "1     Thank you for your interest in the Train To Hi...\n",
       "2     eth, Thank you for your interest in Exyn and f...\n",
       "3     Thank you for your interest in the Software En...\n",
       "4     Hi Seth,Thank you for your interest in PathAI!...\n",
       "...                                                 ...\n",
       "1580  Blue skies and good self-care ahead... Manage ...\n",
       "1581  If not, these fragrance will have you ready! M...\n",
       "1582  Colourful makeup that will literally bloom on ...\n",
       "1583  Get access to your customized training plan th...\n",
       "1584  ”‘ Unlock all of our Coach features and take y...\n",
       "\n",
       "[13074 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for w in replace_list:\n",
    "    df_merge['Text'] = df_merge['Text'].str.replace(w, '')\n",
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\karan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\karan\\AppData\\Local\\Temp\\ipykernel_7852\\1792012154.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merge['transformed_text'] = df_merge['Text'].apply(lambda x: transform_text2(x))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def transform_text2(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = nltk.word_tokenize(text)\n",
    "\n",
    "        y = []\n",
    "        for i in text:\n",
    "            if i.isalnum():\n",
    "                y.append(i)\n",
    "\n",
    "        text = y[:]\n",
    "        y.clear()\n",
    "\n",
    "        for i in text:\n",
    "            if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "                y.append(lemmatizer.lemmatize(i))\n",
    "\n",
    "        return \" \".join(y)\n",
    "    else:\n",
    "        \n",
    "        return str(text)  # Convert non-string types to string\n",
    "\n",
    "# Apply the modified transform_text2 function using lambda to the 'Text' column\n",
    "df_merge['transformed_text'] = df_merge['Text'].apply(lambda x: transform_text2(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you for applying to the Junior Software ...</td>\n",
       "      <td>thank applying junior software developer posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you for your interest in the Train To Hi...</td>\n",
       "      <td>thank interest train hire junior software deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eth, Thank you for your interest in Exyn and f...</td>\n",
       "      <td>eth thank interest exyn applying apart team so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you for your interest in the Software En...</td>\n",
       "      <td>thank interest software engineer position lant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi Seth,Thank you for your interest in PathAI!...</td>\n",
       "      <td>hi seth thank interest pathai unfortunately hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>Blue skies and good self-care ahead... Manage ...</td>\n",
       "      <td>blue sky good ahead manage mailing preference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>If not, these fragrance will have you ready! M...</td>\n",
       "      <td>fragrance ready manage mailing preference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>Colourful makeup that will literally bloom on ...</td>\n",
       "      <td>colourful makeup literally bloom face manage m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>Get access to your customized training plan th...</td>\n",
       "      <td>get access customized training plan 39 motivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>”‘ Unlock all of our Coach features and take y...</td>\n",
       "      <td>unlock coach feature take training next level ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13074 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0     Thank you for applying to the Junior Software ...   \n",
       "1     Thank you for your interest in the Train To Hi...   \n",
       "2     eth, Thank you for your interest in Exyn and f...   \n",
       "3     Thank you for your interest in the Software En...   \n",
       "4     Hi Seth,Thank you for your interest in PathAI!...   \n",
       "...                                                 ...   \n",
       "1580  Blue skies and good self-care ahead... Manage ...   \n",
       "1581  If not, these fragrance will have you ready! M...   \n",
       "1582  Colourful makeup that will literally bloom on ...   \n",
       "1583  Get access to your customized training plan th...   \n",
       "1584  ”‘ Unlock all of our Coach features and take y...   \n",
       "\n",
       "                                       transformed_text  \n",
       "0     thank applying junior software developer posit...  \n",
       "1     thank interest train hire junior software deve...  \n",
       "2     eth thank interest exyn applying apart team so...  \n",
       "3     thank interest software engineer position lant...  \n",
       "4     hi seth thank interest pathai unfortunately hi...  \n",
       "...                                                 ...  \n",
       "1580      blue sky good ahead manage mailing preference  \n",
       "1581          fragrance ready manage mailing preference  \n",
       "1582  colourful makeup literally bloom face manage m...  \n",
       "1583  get access customized training plan 39 motivat...  \n",
       "1584  unlock coach feature take training next level ...  \n",
       "\n",
       "[13074 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Manually checking if the cleaning worked\n",
    "# df_merge = pd.read_excel(r\"C:\\Users\\karan\\Desktop\\NLP_DATA\\NLP_CaseStudy_Cleaned.xlsx\")\n",
    "# df_merge.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS TAGGING\n",
    "#Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "from nltk.corpus import wordnet\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform part-of-speech tagging and create a new column 'wordnet_tagged'\n",
    "df_merge['wordnet_tagged'] = df['cleaned'].apply(lambda tokens: [(word, pos_tagger(tag)) for word, tag in nltk.pos_tag(tokens)])\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to lemmatize a token based on its POS tag\n",
    "def lemmatize_word(word, pos_tag):\n",
    "    if pos_tag is not None:\n",
    "        return lemmatizer.lemmatize(word, pos=pos_tag)\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word)\n",
    "\n",
    "# Apply the lemmatization function to the 'wordnet_tagged' column\n",
    "df['lemmatized_text'] = df['wordnet_tagged'].apply(lambda tagged_tokens: [lemmatize_word(word, pos_tag) for word, pos_tag in tagged_tokens])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\karan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\karan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\karan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\karan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "C:\\Users\\karan\\AppData\\Local\\Temp\\ipykernel_7852\\983245522.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merge['lemmatized_text'] = df_merge['transformed_text'].apply(lambda x: lemmatize_and_pos_tag(x))\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_and_pos_tag(text):\n",
    "    if isinstance(text, str):\n",
    "        text = nltk.word_tokenize(text)\n",
    "\n",
    "        y = []\n",
    "        for word, pos in nltk.pos_tag(text):\n",
    "            if word.isalnum() and word not in stopwords.words('english') and word not in string.punctuation:\n",
    "                pos = pos[0].lower()  # Get the first letter of the POS tag\n",
    "                if pos in {'a', 'n', 'v'}:  # Consider only adjectives, nouns, and verbs for lemmatization\n",
    "                    y.append(lemmatizer.lemmatize(word, pos))\n",
    "                else:\n",
    "                    y.append(word)\n",
    "\n",
    "        return \" \".join(y)\n",
    "    else:\n",
    "        return str(text)  # Convert non-string types to string\n",
    "\n",
    "# Apply the lemmatize_and_pos_tag function using lambda to the 'Text' column\n",
    "df_merge['lemmatized_text'] = df_merge['transformed_text'].apply(lambda x: lemmatize_and_pos_tag(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>transformed_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thank you for applying to the Junior Software ...</td>\n",
       "      <td>thank applying junior software developer posit...</td>\n",
       "      <td>thank apply junior software developer position...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you for your interest in the Train To Hi...</td>\n",
       "      <td>thank interest train hire junior software deve...</td>\n",
       "      <td>thank interest train hire junior software deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eth, Thank you for your interest in Exyn and f...</td>\n",
       "      <td>eth thank interest exyn applying apart team so...</td>\n",
       "      <td>eth thank interest exyn apply apart team softw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thank you for your interest in the Software En...</td>\n",
       "      <td>thank interest software engineer position lant...</td>\n",
       "      <td>thank interest software engineer position lant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi Seth,Thank you for your interest in PathAI!...</td>\n",
       "      <td>hi seth thank interest pathai unfortunately hi...</td>\n",
       "      <td>hi seth thank interest pathai unfortunately hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>Blue skies and good self-care ahead... Manage ...</td>\n",
       "      <td>blue sky good ahead manage mailing preference</td>\n",
       "      <td>blue sky good ahead manage mailing preference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>If not, these fragrance will have you ready! M...</td>\n",
       "      <td>fragrance ready manage mailing preference</td>\n",
       "      <td>fragrance ready manage mail preference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>Colourful makeup that will literally bloom on ...</td>\n",
       "      <td>colourful makeup literally bloom face manage m...</td>\n",
       "      <td>colourful makeup literally bloom face manage m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>Get access to your customized training plan th...</td>\n",
       "      <td>get access customized training plan 39 motivat...</td>\n",
       "      <td>get access customize training plan 39 motivate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>”‘ Unlock all of our Coach features and take y...</td>\n",
       "      <td>unlock coach feature take training next level ...</td>\n",
       "      <td>unlock coach feature take training next level ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13074 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  \\\n",
       "0     Thank you for applying to the Junior Software ...   \n",
       "1     Thank you for your interest in the Train To Hi...   \n",
       "2     eth, Thank you for your interest in Exyn and f...   \n",
       "3     Thank you for your interest in the Software En...   \n",
       "4     Hi Seth,Thank you for your interest in PathAI!...   \n",
       "...                                                 ...   \n",
       "1580  Blue skies and good self-care ahead... Manage ...   \n",
       "1581  If not, these fragrance will have you ready! M...   \n",
       "1582  Colourful makeup that will literally bloom on ...   \n",
       "1583  Get access to your customized training plan th...   \n",
       "1584  ”‘ Unlock all of our Coach features and take y...   \n",
       "\n",
       "                                       transformed_text  \\\n",
       "0     thank applying junior software developer posit...   \n",
       "1     thank interest train hire junior software deve...   \n",
       "2     eth thank interest exyn applying apart team so...   \n",
       "3     thank interest software engineer position lant...   \n",
       "4     hi seth thank interest pathai unfortunately hi...   \n",
       "...                                                 ...   \n",
       "1580      blue sky good ahead manage mailing preference   \n",
       "1581          fragrance ready manage mailing preference   \n",
       "1582  colourful makeup literally bloom face manage m...   \n",
       "1583  get access customized training plan 39 motivat...   \n",
       "1584  unlock coach feature take training next level ...   \n",
       "\n",
       "                                        lemmatized_text  \n",
       "0     thank apply junior software developer position...  \n",
       "1     thank interest train hire junior software deve...  \n",
       "2     eth thank interest exyn apply apart team softw...  \n",
       "3     thank interest software engineer position lant...  \n",
       "4     hi seth thank interest pathai unfortunately hi...  \n",
       "...                                                 ...  \n",
       "1580      blue sky good ahead manage mailing preference  \n",
       "1581             fragrance ready manage mail preference  \n",
       "1582  colourful makeup literally bloom face manage m...  \n",
       "1583  get access customize training plan 39 motivate...  \n",
       "1584  unlock coach feature take training next level ...  \n",
       "\n",
       "[13074 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.to_excel(r\"C:\\Users\\karan\\Desktop\\NLP_DATA\\NLP_CaseStudy_Cleaned1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
